# Stanford CS224n Natural Language Processing with Deep Learning

The course notes about Stanford CS224n Winter 2019 (using PyTorch)

> Some general notes I'll write in [my Deep Learning Practice repository](https://github.com/daviddwlee84/DeepLearningPractice)

Course Related Links

* [CS224n: Natural Language Processing with Deep Learning](http://web.stanford.edu/class/cs224n/)
* [Lecture Videos](https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z)

## Schedule

| Week         | Lectures                                                                  | Assignments                                          |
| ------------ | ------------------------------------------------------------------------- | ---------------------------------------------------- |
| 2019/7/1~7/7 | [Introduction and Word Vectors](#Lecture-1-Introduction-and-Word-Vectors), [Word Vectors 2 and Word Senses](#Lecture-2-Word-Vectors-2-and-Word-Senses) | [Assignment 1](#Assignment-1-Exploring-Word-Vectors) |

### Lectures

#### Lecture 1: Introduction and Word Vectors

* [slides](CourseMaterials/slides/cs224n-2019-lecture01-wordvecs1.pdf)
* [notes](CourseMaterials/notes/cs224n-2019-notes01-wordvecs1.pdf)
* readings
  * [ ] [Word2Vec Tutorial - The Skip-Gram Model](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)
  * [ ] [Efficient Estimation of Word Representations in Vector Space (original word2vec paper)](CourseMaterials/readings/word2vec.pdf)
  * [ ] [Distributed Representations of Words and Phrases and their Compositionality (negative sampling paper)](CourseMaterials/readings/NegativeSampling.pdf)
* [Gensim example](CourseMaterials/GensimWordVectorVisualization.ipynb)

#### Lecture 2: Word Vectors 2 and Word Senses

* [slides](CourseMaterials/slides/cs224n-2019-lecture02-wordvecs2.pdf)
* [notes](CourseMaterials/notes/cs224n-2019-notes02-wordvecs2.pdf)
* readings
  * [ ] [GloVe: Global Vectors for Word Representation (original GloVe paper)](CourseMaterials/readings/glove.pdf)
  * [ ] [Improving Distributional Similarity with Lessons Learned from Word Embeddings](CourseMaterials/readings/ImprovingDistributionalSimilarity.pdf)
  * [ ] [Evaluation methods for unsupervised word embeddings](CourseMaterials/readings/EmbeddingEvaluationMethods.pdf)
* additional readings
  * [ ] [A Latent Variable Model Approach to PMI-based Word Embeddings](CourseMaterials/additional/PMI-basedWordEmbeddings.pdf)
  * [ ] [Linear Algebraic Structure of Word Senses, with Applications to Polysemy](CourseMaterials/additional/LinearAlgebraicStructureOfWordSenses.pdf)
  * [ ] [On the Dimensionality of Word Embedding](CourseMaterials/additional/DimensionalityOfWordEmbedding.pdf)

### Assignments

#### Assignment 1: Exploring Word Vectors

* [code](Assignments/a1)
